# -*- coding: utf-8 -*-
"""Waste_Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Uq__F0iruBva6jWapooXpGNO6QZhofht
"""

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from skimage.io import imread
from skimage.transform import resize
from keras.layers import Dense,Conv2D,MaxPool2D
import warnings
warnings.filterwarnings('ignore')

import random
random.seed(1)0

path = '/content/drive/MyDrive/RealWaste'
categories = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash',
              'Paper', 'Plastic', 'Textile Trash', 'Vegetation']

X = []
y = []
category_counts = {}
for category in categories:
    fold_path = os.path.join(path, category)
    images = os.listdir(fold_path)
    category_counts[category] = len(images)

    for img in images:
        img_path = os.path.join(fold_path, img)

        try:
            img_array = imread(img_path)
            img_resized = resize(img_array, (150, 150), anti_aliasing=True)
            X.append(img_resized)
            y.append(categories.index(category))
        except Exception as e:
            print(f"Error loading image {img_path}: {e}")

    print(f"Loaded category: {category} ({len(images)} images)")

X = np.array(X)
y = np.array(y)
df_counts = pd.DataFrame(list(category_counts.items()), columns=["Category", "Image Count"])
df_counts = df_counts.sort_values(by="Image Count", ascending=False)


plt.figure(figsize=(10, 5))
sns.barplot(x=df_counts["Image Count"], y=df_counts["Category"], palette="viridis")
plt.xlabel("Number of Images")
plt.ylabel("Waste Category")
plt.title("Distribution of Images in RealWaste Dataset")
plt.show()

# Shuffle dataset to ensure random distribution
indices = np.arange(len(X))  # Create an index array
np.random.shuffle(indices)  # Shuffle indices

# Define split ratio
split_ratio = 0.8  # 80% train, 20% test
split_index = int(len(X) * split_ratio)

# Split the dataset
X_train, X_test = X[indices[:split_index]], X[indices[split_index:]]
y_train, y_test = y[indices[:split_index]], y[indices[split_index:]]

# Print dataset shapes
print("Training set shape:", X_train.shape, y_train.shape)
print("Testing set shape:", X_test.shape, y_test.shape)

from keras.models import Sequential
from keras.layers import Flatten
model=Sequential()
#convolution layer
model.add(Conv2D(32,(3,3),activation='relu'))
#pooling layer
model.add(MaxPool2D(2,2))  #if stride is not mentioned the size of pooling layer is taken as stride value
model.add(Conv2D(32,(3,3),activation='relu'))
model.add(MaxPool2D(2,2))
#flatten layer
model.add(Flatten())
#add dense layer
model.add(Dense(100,activation='relu'))
model.add(Dense(9,activation='softmax'))

model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

model.fit(X_train,y_train,epochs=100,batch_size=32)